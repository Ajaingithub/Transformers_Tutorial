{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be60f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "### How it is going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f5bd975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163f3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "os.chdir('/mnt/data/projects/.immune/Personal/Transformers_Tutorial/')\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "954a16bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])  # print the first 1000 characters to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d2bb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the unique characters: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Vocab size: 65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"All the unique characters:\", ''.join(chars))\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b703c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42]\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "# creating a mapping from characters to integers\n",
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]  # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l])  # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"hello world\"))\n",
    "print(decode(encode(\"hello world\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8685bfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) <built-in method type of Tensor object at 0x7f3531567600>\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# lets encode the entire text into the integer representation\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape,data.type)\n",
    "print(data[:1000])  # first 1000 characters encoded as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddf27552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into train and val sets\n",
    "n = int(0.9*len(data))  # first 90% will be\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc4d9642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8  # context length for predictions\n",
    "train_data[:block_size+1] ### till 8 it will be train and 9th character is the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "769b18e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Cit\n"
     ]
    }
   ],
   "source": [
    "print(decode(train_data[:block_size+1].tolist()))  # checking if decoding works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "516fec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is 'F' the target: 'i'\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is 'Fi' the target: 'r'\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is 'Fir' the target: 's'\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is 'Firs' the target: 't'\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is 'First' the target: ' '\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is 'First ' the target: 'C'\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is 'First C' the target: 'i'\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n",
      "when input is 'First Ci' the target: 't'\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]  # input\n",
    "y = train_data[1:block_size+1]  # target\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]  # the context grows with t\n",
    "    target = y[t]     # the target is always the next character\n",
    "    print(f'when input is {context} the target: {target}')\n",
    "    print(f\"when input is {decode(context.tolist())!r} the target: {decode([target.tolist()])!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1855f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "y: tensor([47, 56, 57, 58,  1, 15, 47, 58])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4  # parallel sequences processing\n",
    "block_size = 8  # context length for predictions\n",
    "\n",
    "train_data.shape, val_data.shape\n",
    "data = train_data\n",
    "ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "y - torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a41f2d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "when input is tensor([24]) the target: 43\n",
      "when input is 'L' the target: 'e'\n",
      "when input is tensor([24, 43]) the target: 58\n",
      "when input is 'Le' the target: 't'\n",
      "when input is tensor([24, 43, 58]) the target: 5\n",
      "when input is 'Let' the target: \"'\"\n",
      "when input is tensor([24, 43, 58,  5]) the target: 57\n",
      "when input is \"Let'\" the target: 's'\n",
      "when input is tensor([24, 43, 58,  5, 57]) the target: 1\n",
      "when input is \"Let's\" the target: ' '\n",
      "when input is tensor([24, 43, 58,  5, 57,  1]) the target: 46\n",
      "when input is \"Let's \" the target: 'h'\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46]) the target: 43\n",
      "when input is \"Let's h\" the target: 'e'\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46, 43]) the target: 39\n",
      "when input is \"Let's he\" the target: 'a'\n",
      "when input is tensor([44]) the target: 53\n",
      "when input is 'f' the target: 'o'\n",
      "when input is tensor([44, 53]) the target: 56\n",
      "when input is 'fo' the target: 'r'\n",
      "when input is tensor([44, 53, 56]) the target: 1\n",
      "when input is 'for' the target: ' '\n",
      "when input is tensor([44, 53, 56,  1]) the target: 58\n",
      "when input is 'for ' the target: 't'\n",
      "when input is tensor([44, 53, 56,  1, 58]) the target: 46\n",
      "when input is 'for t' the target: 'h'\n",
      "when input is tensor([44, 53, 56,  1, 58, 46]) the target: 39\n",
      "when input is 'for th' the target: 'a'\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39]) the target: 58\n",
      "when input is 'for tha' the target: 't'\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39, 58]) the target: 1\n",
      "when input is 'for that' the target: ' '\n",
      "when input is tensor([52]) the target: 58\n",
      "when input is 'n' the target: 't'\n",
      "when input is tensor([52, 58]) the target: 1\n",
      "when input is 'nt' the target: ' '\n",
      "when input is tensor([52, 58,  1]) the target: 58\n",
      "when input is 'nt ' the target: 't'\n",
      "when input is tensor([52, 58,  1, 58]) the target: 46\n",
      "when input is 'nt t' the target: 'h'\n",
      "when input is tensor([52, 58,  1, 58, 46]) the target: 39\n",
      "when input is 'nt th' the target: 'a'\n",
      "when input is tensor([52, 58,  1, 58, 46, 39]) the target: 58\n",
      "when input is 'nt tha' the target: 't'\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58]) the target: 1\n",
      "when input is 'nt that' the target: ' '\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58,  1]) the target: 46\n",
      "when input is 'nt that ' the target: 'h'\n",
      "when input is tensor([25]) the target: 17\n",
      "when input is 'M' the target: 'E'\n",
      "when input is tensor([25, 17]) the target: 27\n",
      "when input is 'ME' the target: 'O'\n",
      "when input is tensor([25, 17, 27]) the target: 10\n",
      "when input is 'MEO' the target: ':'\n",
      "when input is tensor([25, 17, 27, 10]) the target: 0\n",
      "when input is 'MEO:' the target: '\\n'\n",
      "when input is tensor([25, 17, 27, 10,  0]) the target: 21\n",
      "when input is 'MEO:\\n' the target: 'I'\n",
      "when input is tensor([25, 17, 27, 10,  0, 21]) the target: 1\n",
      "when input is 'MEO:\\nI' the target: ' '\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1]) the target: 54\n",
      "when input is 'MEO:\\nI ' the target: 'p'\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1, 54]) the target: 39\n",
      "when input is 'MEO:\\nI p' the target: 'a'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4  # parallel sequences processing\n",
    "block_size = 8  # context length for predictions\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))  # random starting indices\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])  # input sequences\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])  # target sequences\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f'when input is {context} the target: {target}')\n",
    "        print(f\"when input is {decode(context.tolist())!r} the target: {decode([target.tolist()])!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cebd26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: tensor([[-1.5101, -0.0948,  1.0927,  ..., -0.6126, -0.6597,  0.7624],\n",
      "        [ 0.3323, -0.0872, -0.7470,  ..., -0.6716, -0.9572, -0.9594],\n",
      "        [ 0.2475, -0.6349, -1.2909,  ...,  1.3064, -0.2256, -1.8305],\n",
      "        ...,\n",
      "        [-2.1910, -0.7574,  1.9656,  ..., -0.3580,  0.8585, -0.6161],\n",
      "        [ 0.5978, -0.0514, -0.0646,  ..., -1.4649, -2.0555,  1.8275],\n",
      "        [-0.6787,  0.8662, -1.6433,  ...,  2.3671, -0.7775, -0.2586]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "loss: tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([32, 65])\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "# Constructing the bigram model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size) # this is random initialization which will be learned during training.\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B,T) tensor of integers where idx is xb and targets is yb\n",
    "        logits = self.token_embedding_table(idx)  # (B,T,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens): # Throw-away variable in loops so it does not fill the variable memory.\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx) # Calls the Forward method\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # (B,C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)  # (B,C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B,1) #  draws a sample from the probability distribution. It returns the index of the next chosen token.\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B,T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb) # PyTorch overloads the __call__() method of nn.Module. This calls the forward() method. \n",
    "print(\"logits:\", logits)\n",
    "print(\"loss:\", loss)\n",
    "print(logits.shape) # (B*T, C)\n",
    "# print(targets.shape) # (B*T, C)\n",
    "# torch.zeroes is for new line character so we can initialize the generation from it.\n",
    "# This is completely random generation as the model is untrained.\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a549fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7c1d1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 65])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44f47a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.6243, -0.1004,  0.2456,  ..., -1.2338,  0.0534, -0.1949],\n",
       "        [ 0.8603, -0.2675, -0.4354,  ..., -0.1845, -1.0497, -0.8261],\n",
       "        [ 1.7343,  0.8752,  1.5813,  ...,  1.2927,  0.7182,  0.6097],\n",
       "        ...,\n",
       "        [-1.6689, -3.3766, -0.4560,  ...,  0.2780, -1.5953, -0.4737],\n",
       "        [-1.2969,  1.8702, -1.0598,  ..., -1.2579,  0.1119,  0.3389],\n",
       "        [-0.0886, -1.0879,  0.9975,  ..., -1.2604,  0.8044, -1.9819]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embedding=nn.Embedding(vocab_size, vocab_size)\n",
    "token_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a829f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = token_embedding(xb) # (B,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0592b799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3660e-01, -1.8731e+00,  7.1989e-01,  1.3609e-01,  9.8589e-01,\n",
      "          1.5483e+00, -2.6414e-01, -1.1776e+00,  5.1714e-01, -4.6053e-01,\n",
      "          4.2017e-01, -9.6025e-01,  1.3287e+00,  2.0909e-01,  8.6215e-01,\n",
      "          4.3085e-02,  5.7950e-01, -2.0212e+00, -8.1185e-01,  6.5908e-01,\n",
      "         -7.5360e-02,  1.3957e+00,  2.0643e+00, -2.0412e+00, -3.7620e-01,\n",
      "         -3.8499e-01,  3.5262e-01, -4.5423e-01,  1.1916e+00, -8.5033e-01,\n",
      "         -1.1318e+00,  9.0647e-01,  5.6884e-01, -2.9375e+00,  4.6553e-01,\n",
      "         -9.6770e-01, -1.4652e+00, -2.6071e-01, -1.0342e+00, -1.3620e+00,\n",
      "         -1.2595e+00, -1.8476e+00,  1.1339e+00, -2.0390e-01,  2.8299e-01,\n",
      "          3.1425e-01,  1.5377e+00,  9.7995e-02,  1.5568e-01, -3.9144e-01,\n",
      "         -1.0180e+00,  2.9127e-01, -1.4972e+00,  8.3221e-01,  1.5373e+00,\n",
      "         -1.1809e+00,  2.8087e+00,  1.7374e+00, -5.5859e-01, -8.0195e-01,\n",
      "         -5.1946e-01, -9.9884e-01,  2.1045e-01,  8.7487e-01,  2.4380e-01],\n",
      "        [ 4.1719e-01,  6.3408e-01, -1.8520e+00,  1.3329e+00, -2.3835e-01,\n",
      "         -8.3095e-01,  3.6281e-01,  2.8096e-01,  4.8274e-01,  1.9110e+00,\n",
      "         -1.3013e-01, -1.1725e+00, -6.3693e-01, -1.8083e-01, -8.8123e-01,\n",
      "          7.9419e-01,  1.5290e-01,  1.3080e+00, -6.3439e-01,  9.1087e-01,\n",
      "          9.4972e-01, -1.6114e+00,  8.5771e-02,  1.7488e+00,  1.3325e+00,\n",
      "         -9.7220e-01,  1.6579e-01,  1.0346e+00,  1.0876e-02,  1.3998e-01,\n",
      "          2.1353e+00,  1.2158e+00, -1.5107e+00,  7.4399e-02,  4.2628e-01,\n",
      "          3.6319e-01,  7.7939e-02,  7.5884e-01, -1.3059e+00, -6.2333e-01,\n",
      "         -1.1189e+00,  1.1120e+00,  1.2642e+00,  5.3649e-01,  4.0709e-02,\n",
      "          1.3487e+00,  8.6895e-01, -9.8258e-01,  6.4742e-01,  1.9123e-01,\n",
      "          6.9911e-02,  1.4409e+00,  9.1732e-02, -1.8625e+00, -1.0470e+00,\n",
      "          6.6066e-01, -3.2875e-02,  2.4735e-01,  4.1963e-01,  1.9724e+00,\n",
      "          1.2799e+00,  1.0090e+00, -2.4700e-01, -2.6345e-01, -3.2457e-01],\n",
      "        [ 2.0899e+00, -5.2521e-01, -4.6966e-01, -5.4845e-01,  2.8646e-01,\n",
      "         -7.2916e-01,  6.7663e-01,  5.5633e-01,  8.5716e-01,  1.3767e+00,\n",
      "          4.0655e-01,  9.2928e-01, -2.7701e-01, -3.3431e-01, -8.4452e-01,\n",
      "          4.0344e-01,  6.5026e-01,  2.7022e-01,  3.0861e-01, -2.7157e-01,\n",
      "         -2.8080e+00, -1.6318e+00,  1.0151e-01,  1.5565e+00,  1.2029e+00,\n",
      "          1.5426e+00, -1.8607e-01,  2.1844e-01,  1.0582e+00, -2.2981e-02,\n",
      "          4.4055e-01,  1.3465e+00, -6.4695e-01,  9.9397e-01,  5.2276e-01,\n",
      "          9.9946e-01,  9.7238e-01, -2.0587e+00, -1.2321e+00,  4.3203e-01,\n",
      "         -3.1966e-01, -1.7550e+00, -2.6497e-01,  4.9805e-01,  5.4433e-01,\n",
      "          8.4292e-01,  5.7435e-02,  3.1024e-01, -1.8794e-01,  4.1479e-01,\n",
      "         -2.0570e-01,  1.3358e+00, -1.8638e+00,  1.5129e+00, -1.7818e+00,\n",
      "         -4.6854e-03,  1.7688e+00, -1.0526e-01,  5.9094e-02, -1.3655e+00,\n",
      "          1.3215e+00,  2.6359e-01,  1.4875e+00,  6.6250e-01,  2.5883e+00],\n",
      "        [ 8.3439e-01,  4.8268e-01,  3.2132e-01,  9.8181e-01,  1.1415e+00,\n",
      "          4.6572e-01, -1.2951e+00,  3.4767e-01, -2.0663e+00,  4.9599e-01,\n",
      "         -4.0669e-02, -2.9222e+00, -2.8413e-01,  8.8407e-02, -9.8454e-01,\n",
      "          1.6508e+00, -9.0351e-01, -1.6502e+00, -9.8214e-01,  1.4338e+00,\n",
      "          1.6344e-01, -2.3246e+00, -6.6426e-01,  3.4425e-01,  2.5640e-01,\n",
      "         -1.5011e+00, -1.2276e-01, -1.5234e-01, -7.4305e-01, -1.0599e+00,\n",
      "         -5.3123e-01,  1.1549e+00,  1.3081e+00,  7.3786e-01, -1.6591e+00,\n",
      "         -8.4010e-01, -1.3581e+00,  4.3531e-01, -1.9206e+00,  1.6105e+00,\n",
      "          2.4026e-01, -8.6997e-02, -1.1245e+00, -8.3828e-01,  1.8211e-01,\n",
      "         -2.8415e-01,  9.7605e-01,  2.0496e+00,  1.2779e+00, -5.9809e-01,\n",
      "         -2.0872e-01, -1.8325e+00, -1.8434e-02, -8.9431e-01, -2.6908e-01,\n",
      "          7.7620e-02, -4.9254e-01, -5.6568e-02,  4.7034e-01, -8.4867e-02,\n",
      "         -1.0538e+00,  1.0298e+00, -6.5059e-01,  5.3971e-01, -4.6932e-01],\n",
      "        [ 1.7496e+00, -1.3142e+00, -2.6818e-01, -1.6090e-01,  7.6331e-01,\n",
      "          9.6112e-01, -1.5080e-01, -3.1125e-01, -2.3261e-01, -5.8817e-01,\n",
      "          1.4177e+00, -1.2886e+00,  6.5825e-01, -1.4660e+00, -2.5495e-01,\n",
      "         -1.5867e+00, -1.3033e-01,  2.6345e-01,  8.0033e-01, -2.8147e-01,\n",
      "          4.9364e-01, -1.2931e-01,  1.1039e+00,  2.0847e-01,  3.4679e-01,\n",
      "         -5.4988e-01,  6.4344e-01,  6.0704e-01,  1.3066e+00,  1.8688e+00,\n",
      "         -2.2867e-01, -4.9845e-01,  9.7364e-01,  4.2643e-04, -1.6465e-01,\n",
      "         -5.3298e-01,  8.4407e-01, -1.4206e+00,  1.6876e-01,  3.8585e-01,\n",
      "          6.9129e-01,  4.2996e-01,  9.9014e-01, -7.2189e-01, -9.9551e-01,\n",
      "          8.5943e-01,  1.5289e+00,  1.5251e+00,  1.4120e-01,  1.5508e+00,\n",
      "         -2.6785e-01,  8.5284e-01, -2.0275e+00, -6.9661e-01, -1.5299e+00,\n",
      "          6.5047e-01, -5.7164e-01, -2.4566e-01,  5.7103e-01, -3.7924e-01,\n",
      "          8.6407e-01,  6.0657e-01, -2.9749e-01,  9.4387e-01, -2.1673e+00],\n",
      "        [ 8.6031e-01, -2.6748e-01, -4.3536e-01,  3.9767e-01, -1.5627e-01,\n",
      "         -2.8093e-02,  1.7915e+00, -3.8532e-01,  7.4799e-01,  1.1025e+00,\n",
      "         -1.7147e-01,  4.5868e-01, -2.6170e+00, -1.8637e+00,  1.6446e+00,\n",
      "         -1.4193e+00,  6.3701e-01, -2.0427e+00,  2.6179e-01, -3.8560e-01,\n",
      "         -1.3818e+00,  1.5872e-01,  3.5286e-01,  1.2170e+00, -1.0035e+00,\n",
      "         -5.6401e-01, -1.3432e+00, -5.3805e-01,  7.8276e-01, -9.2205e-01,\n",
      "         -8.4715e-01,  8.3337e-01,  2.1029e-01, -2.3446e-01, -1.3996e-02,\n",
      "          1.0262e+00, -8.9598e-01, -9.6618e-01,  1.0666e+00,  1.3343e+00,\n",
      "         -1.5190e-01,  3.9288e-01,  7.0952e-01,  3.2068e-01, -4.2619e-01,\n",
      "         -6.5384e-02,  1.2530e+00,  2.4880e-01,  7.9830e-01, -1.0938e+00,\n",
      "         -1.1291e-01,  9.6340e-01, -3.0237e-01, -5.6314e-01, -1.3439e-01,\n",
      "         -1.0981e+00,  1.4837e-01, -1.2356e-01, -1.3368e-01, -4.3396e-01,\n",
      "          7.8065e-01,  1.0760e+00, -1.8449e-01, -1.0497e+00, -8.2610e-01],\n",
      "        [-5.5028e-01,  2.4553e-01, -8.1050e-01,  8.0002e-02,  1.6700e+00,\n",
      "         -1.5319e+00,  7.8733e-01,  1.3545e+00,  5.2466e-01,  5.0678e-01,\n",
      "         -8.8718e-01,  7.7248e-01, -6.5893e-02, -5.7829e-01,  3.5940e-01,\n",
      "         -5.0790e-01,  4.0299e-01,  5.2060e-01, -6.6829e-01, -8.8536e-01,\n",
      "          2.8420e-01, -8.6382e-02, -1.2906e+00,  1.1906e+00,  7.8378e-01,\n",
      "         -1.2473e-02, -1.8007e+00, -1.2373e+00,  1.2439e+00,  7.6467e-01,\n",
      "          2.5281e-02, -9.4156e-01,  1.2521e-01,  9.0356e-01, -1.8441e-01,\n",
      "          6.2462e-01, -1.4374e+00, -9.6756e-02,  1.4749e+00,  6.9119e-01,\n",
      "          1.1509e+00, -8.0330e-01,  4.3955e-01, -1.0593e+00,  1.0395e+00,\n",
      "          1.4556e+00,  3.8041e-01, -4.2485e-01,  3.2582e-01,  9.9553e-01,\n",
      "         -3.1884e-01,  1.1425e+00, -7.0066e-01,  1.1699e+00,  4.0563e-01,\n",
      "          3.9237e-01,  3.9008e-01,  8.0120e-01, -1.1087e+00, -1.5223e-01,\n",
      "         -3.5908e-01,  1.2743e+00, -4.7150e-01,  8.0781e-01, -5.7455e-01],\n",
      "        [ 4.1719e-01,  6.3408e-01, -1.8520e+00,  1.3329e+00, -2.3835e-01,\n",
      "         -8.3095e-01,  3.6281e-01,  2.8096e-01,  4.8274e-01,  1.9110e+00,\n",
      "         -1.3013e-01, -1.1725e+00, -6.3693e-01, -1.8083e-01, -8.8123e-01,\n",
      "          7.9419e-01,  1.5290e-01,  1.3080e+00, -6.3439e-01,  9.1087e-01,\n",
      "          9.4972e-01, -1.6114e+00,  8.5771e-02,  1.7488e+00,  1.3325e+00,\n",
      "         -9.7220e-01,  1.6579e-01,  1.0346e+00,  1.0876e-02,  1.3998e-01,\n",
      "          2.1353e+00,  1.2158e+00, -1.5107e+00,  7.4399e-02,  4.2628e-01,\n",
      "          3.6319e-01,  7.7939e-02,  7.5884e-01, -1.3059e+00, -6.2333e-01,\n",
      "         -1.1189e+00,  1.1120e+00,  1.2642e+00,  5.3649e-01,  4.0709e-02,\n",
      "          1.3487e+00,  8.6895e-01, -9.8258e-01,  6.4742e-01,  1.9123e-01,\n",
      "          6.9911e-02,  1.4409e+00,  9.1732e-02, -1.8625e+00, -1.0470e+00,\n",
      "          6.6066e-01, -3.2875e-02,  2.4735e-01,  4.1963e-01,  1.9724e+00,\n",
      "          1.2799e+00,  1.0090e+00, -2.4700e-01, -2.6345e-01, -3.2457e-01]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([4, 8])\n",
      "torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "print(logits[0])\n",
    "print(loss)\n",
    "print(xb.shape) # B X T\n",
    "print(yb.shape) # B X T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215e376e",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6b39d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6be7835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6904830932617188\n"
     ]
    }
   ],
   "source": [
    "for steps in range(10000):\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    # optimize the model\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34df302b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ss d tcI:\n",
      "AUNorthiref s is, XLANzncouso;AUCl\n",
      "AHllico ithen, Horeo t had,\n",
      "\n",
      "Mh\n",
      "FINolly\n",
      "\n",
      "\n",
      "\n",
      "Uy ou ttirve\n",
      "' ll ato, s then w; s w\n",
      "EQzL:CEXR:\n",
      "Whas nsu bfof; cond,\n",
      "\n",
      "IFtrune e fo wa at we al\n",
      "Cid thind ad cas;\n",
      "Youtod,\n",
      "Fo s mp aSwhy'lout.\n",
      "RFXWathininoth itethe t r; terus rs t;\n",
      "vell COUCENET:\n",
      "bints tes?$a:\n",
      "OLk'douid ours;\n",
      "p' w'raver:\n",
      "\n",
      "e,\n",
      "AUA c,\n",
      "UcousexFIEOr orous sthVIOLinr om!\n",
      "STEDICHe kenf tis bau d IU horf t q.\n",
      "bur,\n",
      "Issthe; rinodvely,V&ven tang, horche.?\n",
      "Thaceayousomege, thage pe'se.\n",
      "ORYQ!ve\n",
      "JFVbep On s\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217cab2c",
   "metadata": {},
   "source": [
    "## The mathematical trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f2c0aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "## This is for 2 dimesnional matrix multiplication\n",
    "# Since in transformer we will be using 2D matrices for attention calculations.\n",
    "# In attention we use only those character before the current character for prediction.\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3)) # Lower triangular matrix\n",
    "a = a / torch.sum(a, dim=1, keepdim=True) # scaling the rows to sum to 1\n",
    "print(a)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "print(b)\n",
    "c = a @ b\n",
    "print(c) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f23b2f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 3])\n",
      "torch.Size([3, 2])\n",
      "torch.Size([3, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "## This is for 2 dimesnional matrix multiplication\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3,4,3)) # Lower triangular matrix\n",
    "a = a / torch.sum(a, dim=1, keepdim=True) # scaling the rows to sum to 1\n",
    "# print(a)\n",
    "print(a.shape)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "# print(b)\n",
    "print(b.shape)\n",
    "c = a @ b\n",
    "# print(c)\n",
    "print(c.shape)\n",
    "# so regarding the dimensions, a = (3,4,3) and b = (3,2) results in c = (3,4,2)\n",
    "# since b = (3,3,2) and while matrix multiplication the last two dimensions are considered for multiplication.\n",
    "# so a = (4,3) and b = (3,2) results in c = (4,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f477f1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.3596, -0.9152],\n",
      "        [ 0.6258,  0.0255],\n",
      "        [ 0.9545,  0.0643],\n",
      "        [ 0.3612,  1.1679],\n",
      "        [-1.3499, -0.5102],\n",
      "        [ 0.2360, -0.2398],\n",
      "        [-0.9211,  1.5433]])\n"
     ]
    }
   ],
   "source": [
    "# try out on our dataset\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be360058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n",
      "torch.Size([4, 8, 2])\n",
      "tensor([[ 0.1808, -0.0700],\n",
      "        [-0.0894, -0.4926],\n",
      "        [ 0.1490, -0.3199],\n",
      "        [ 0.3504, -0.2238],\n",
      "        [ 0.3525,  0.0545],\n",
      "        [ 0.0688, -0.0396],\n",
      "        [ 0.0927, -0.0682],\n",
      "        [-0.0341,  0.1332]])\n"
     ]
    }
   ],
   "source": [
    "### In the self attention here we are just averaging the previous tokens to get a sense of context.\n",
    "\n",
    "xbow = torch.zeros((B, T, C))\n",
    "print(xbow.shape)\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]\n",
    "        xbow[b,t] = torch.mean(xprev,0) # averaging the previous tokens including the current token\n",
    "print(xbow.shape)\n",
    "print(xbow[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61dac0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
      "torch.Size([4, 8, 2])\n",
      "tensor([[ 1.3488, -0.1396],\n",
      "        [ 0.8173,  0.4127],\n",
      "        [-0.1342,  0.4395],\n",
      "        [ 0.2711,  0.4774],\n",
      "        [ 0.2421,  0.0694],\n",
      "        [ 0.0084,  0.0020],\n",
      "        [ 0.0712, -0.1128],\n",
      "        [ 0.2527,  0.2149]])\n",
      "tensor([[ 1.3488, -0.1396],\n",
      "        [ 0.8173,  0.4127],\n",
      "        [-0.1342,  0.4395],\n",
      "        [ 0.2711,  0.4774],\n",
      "        [ 0.2421,  0.0694],\n",
      "        [ 0.0084,  0.0020],\n",
      "        [ 0.0712, -0.1128],\n",
      "        [ 0.2527,  0.2149]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Another more efficient way\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / torch.sum(wei, dim=1, keepdim=True)  #\n",
    "print(wei)\n",
    "xbow2 = wei @ x  # (T,T) @ (T,C) -->\n",
    "print(xbow2.shape)\n",
    "print(xbow2[1])\n",
    "print(xbow[1])\n",
    "torch.allclose(xbow[0], xbow2[0]) ### it is same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2fc2ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8a940e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.zeros((T,T))\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd99d8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### how much does the previous elements contribute to the current element. \n",
    "# so we can use the softmax which is kind of the normalization\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "print(wei)\n",
    "wei = F.softmax(wei, dim = -1)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f115651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: tensor([[ 0.6532, -0.5768,  0.1623,  ...,  0.9086, -0.3203, -0.5369],\n",
      "        [ 0.4420,  0.1231,  0.8807,  ...,  0.5617,  0.1265,  0.2913],\n",
      "        [ 1.0582, -0.5045,  0.3036,  ..., -0.3142,  0.5471,  0.7962],\n",
      "        ...,\n",
      "        [-0.1580, -0.4475,  0.3257,  ...,  0.1921,  0.7424,  0.4570],\n",
      "        [ 0.4546, -0.3635,  0.2983,  ...,  0.2652,  0.5731,  0.0840],\n",
      "        [-0.6873, -0.4842,  0.6730,  ..., -0.5416, -0.7946, -0.7934]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "loss: tensor(4.2468, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([32, 65])\n",
      "\n",
      "lN!BJ'kysLCMFJPKOL?DP-QWwrEoL?jLDJQOL.f'RIHD'Hdhs Yv,wxatnscMZwtEOS'palkq3ssZeAvzF-QT;eMk;x.gQSFCLgx\n"
     ]
    }
   ],
   "source": [
    "# Constructing the bigram model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_emb) # this is random initialization which will be learned during training.\n",
    "        self.lm_head = nn.Linear(n_emb, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B,T) tensor of integers where idx is xb and targets is yb\n",
    "        token_emb = self.token_embedding_table(idx)  # (B,T,C)\n",
    "        logits = self.lm_head(token_emb)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens): # Throw-away variable in loops so it does not fill the variable memory.\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx) # Calls the Forward method\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # (B,C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)  # (B,C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B,1) #  draws a sample from the probability distribution. It returns the index of the next chosen token.\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B,T+1)\n",
    "        return idx\n",
    "\n",
    "n_emb = 32\n",
    "batch_size = 32\n",
    "m = BigramLanguageModel()\n",
    "logits, loss = m(xb, yb) # PyTorch overloads the __call__() method of nn.Module. This calls the forward() method. \n",
    "print(\"logits:\", logits)\n",
    "print(\"loss:\", loss)\n",
    "print(logits.shape) # (B*T, C)\n",
    "# print(targets.shape) # (B*T, C)\n",
    "# torch.zeroes is for new line character so we can initialize the generation from it.\n",
    "# This is completely random generation as the model is untrained.\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2a13cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a3b9a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5342628955841064\n"
     ]
    }
   ],
   "source": [
    "## Training a model\n",
    "for steps in range(10000):\n",
    "    xb,yb = get_batch('train')\n",
    "    logits, loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c763db66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Th thalldy hangilyoteng h hasbe pan hatrance\n",
      "RDe hicomyonthar's\n",
      "PES:\n",
      "AKEd ith henoungincenonthiousir thondy, y heltieiengerofo'dsssit ey\n",
      "KINld pe wither vouprrouthercckeha t,\n",
      "K:\n",
      "\n",
      "My hind tt hinig t ouchos tes; st younind wotte grotonear 'so it t jod weancothanan hay. t--s n prids, r loncave w hollular e O:\n",
      "HIs; ht anje caike ineent.\n",
      "\n",
      "Lavinde.\n",
      "athave l.\n",
      "KEONH:\n",
      "ARThanco be y,-hedarwnoddy scace, aridesar, wyonthenous aves, theresseys\n",
      "Plorseelapinghiybend yof GLANCHI me. strsithisgothers w de o! ABe\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3a356b",
   "metadata": {},
   "source": [
    "#### Adding the Position Embedding to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4ea429c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27ec4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "## First lets initialize \n",
    "vocab_size = 65 # since in the Shakespeare vocabulary has 65 characters \n",
    "emb_size = 128 # total number of dimensions\n",
    "batch_size = 32 # batch size\n",
    "token_size = 8\n",
    "## It is just randomly creating an embedding for all the vocabulary and Tokens with 128 dimensions\n",
    "token_embedding_table = nn.Embedding(vocab_size, emb_size) \n",
    "token_position_table = nn.Embedding(token_size, emb_size)\n",
    "lm_head = nn.Linear(emb_size, vocab_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abfa9a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "character embedding\n",
      "Embedding(65, 128)\n",
      "torch.Size([128])\n",
      "position embedding\n",
      "Embedding(8, 128)\n",
      "torch.Size([128])\n",
      "linear Model\n",
      "Linear(in_features=128, out_features=65, bias=True)\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print(\"character embedding\")\n",
    "print(token_embedding_table)\n",
    "print(token_embedding_table.weight[0,:].shape)\n",
    "# print(token_embedding_table.weight[0,:] )\n",
    "# This shows for first character what is the weight will keep on updating during the backpropogation\n",
    "print(\"position embedding\")\n",
    "print(token_position_table)\n",
    "print(token_position_table.weight[0,:].shape)\n",
    "# print(token_position_table.weight[0,:])\n",
    "# This shows for first token position what is the weight will keep on updating during the backpropogation\n",
    "print(\"linear Model\")\n",
    "print(lm_head)\n",
    "print(lm_head.weight[0,:].shape)\n",
    "# lm_head.weight[0,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "25ffd4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "        token_embedding_table.weight,\n",
    "        token_position_table.weight,\n",
    "        lm_head.weight,\n",
    "        lm_head.bias\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ba422fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0955548286437988\n"
     ]
    }
   ],
   "source": [
    "### After initialization, we will input the values\n",
    "# print(\"Input=\",xb[0:1:10], xb.shape,\"\\nTarget=\",yb[0:1:10], yb.shape)\n",
    "# Now we have to embed these tokens\n",
    "# token_character embedding which will provide us Batch, Token, Embedding 32, 8, 128 (B,T,C)\n",
    "\n",
    "for steps in range(10000):\n",
    "    B,T = xb.shape\n",
    "    token_emb= token_embedding_table(xb)\n",
    "    # print(\"Input_embdding=\",token_emb.shape)\n",
    "    position_emb= token_position_table(torch.arange(T)) ## Since we have to take care of the position\n",
    "    # print(\"Input_pos_embdding=\",position_emb.shape)\n",
    "    x = token_emb + position_emb\n",
    "    # print(\"x=\",x.shape)\n",
    "    logits = lm_head(x) # xW.transpose() + bias\n",
    "    B,T,C = logits.shape\n",
    "    logits3 = logits.view(B*T,C)\n",
    "    # print(\"logits:\",logits3.shape)\n",
    "    targets = yb.view(B*T)\n",
    "    # print('targets:',targets.shape)\n",
    "    loss = F.cross_entropy(logits3, targets)\n",
    "    # optimizer.zero_grad(set_to_none = True)\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    # Gradient reset\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    # Update\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "    # logits2 = logits[:,-1,:]\n",
    "    # print(\"logits=\",logits2.shape)\n",
    "    # prob = F.softmax(logits2, dim = -1)\n",
    "    # print(\"prob=\",prob.shape)\n",
    "    # print(prob.sum(1))\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "73b765f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(idx, max_new_tokens):\n",
    "    # idx: (B, T) tensor of token indices (context). Usually start with [[0]].\n",
    "    for _ in range(max_new_tokens):\n",
    "        B, T = idx.shape\n",
    "        # Forward pass for only the current context\n",
    "        token_emb = token_embedding_table(idx)                         # (B, T, C)\n",
    "        position_emb = token_position_table(torch.arange(T)) # (T, C)\n",
    "        x = token_emb + position_emb                                   # (B, T, C)\n",
    "        logits = lm_head(x)                                            # (B, T, vocab)\n",
    "        # take only the last time step\n",
    "        logits = logits[:, -1, :]                                      # (B, vocab)\n",
    "        # convert logits  probabilities\n",
    "        probs = F.softmax(logits, dim=-1)                              # (B, vocab)\n",
    "        # sample next token\n",
    "        idx_next = torch.multinomial(probs, num_samples=1)             # (B, 1)\n",
    "        # append to sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)                        # (B, T+1)\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bc9be9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KATHAnor\n"
     ]
    }
   ],
   "source": [
    "start = torch.zeros((1, 1), dtype=torch.long)   # context = \"unknown token\" / start token\n",
    "output = generate(start, max_new_tokens=8)\n",
    "print(decode(output[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bca05600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, 23, 13, 45, 43, 56, 60, 39, 47, 49, 43,  1, 61, 47, 49, 43,  1, 61,\n",
      "         47, 49, 43,  1, 46, 39, 52, 51, 39, 47, 49, 43, 52, 41, 47, 49, 43, 57,\n",
      "         43, 56, 57,  1, 63, 43,  1, 51, 39, 52, 49, 43, 57,  1, 61, 47, 49, 43,\n",
      "          1, 51, 39, 47, 49, 43, 57, 47, 49, 43,  1, 61, 47, 49, 43,  1, 41, 46,\n",
      "         63,  1, 59, 54, 53, 51, 39, 52, 53, 52, 41, 47, 49, 43, 56, 60, 39, 52,\n",
      "         41, 39, 48,  1, 39, 52, 41, 47, 49, 43, 57, 43, 57, 43,  1, 61, 47, 49,\n",
      "         43, 58, 46, 47, 49, 43,  1, 52, 53, 58, 63,  1, 51, 39, 52, 41, 47, 49,\n",
      "         43,  1, 46, 39, 52, 41, 47, 49, 43,  1, 44, 44, 44, 43, 52, 58, 39, 52,\n",
      "         53, 52, 53, 49, 43,  1, 44, 44, 56, 47, 49, 43,  1, 61, 47, 49, 43,  1,\n",
      "         41, 47, 49, 43,  1, 59, 54, 53, 51, 59, 54, 53, 56, 53, 58, 63, 43,  1,\n",
      "         59, 54, 53, 51, 39, 52, 58,  1, 44, 44, 44, 44, 43,  1, 51, 39, 52, 58,\n",
      "         39, 52, 58]])\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long)  # or start token / first character\n",
    "generated = context.clone()\n",
    "\n",
    "for _ in range(200):   # generate 200 characters\n",
    "    # crop context to last 8 chars (model's block size)\n",
    "    context_cropped = generated[:, -8:]\n",
    "\n",
    "    token_emb = token_embedding_table(context_cropped)\n",
    "    pos_emb = token_position_table(torch.arange(context_cropped.shape[1]))\n",
    "    x = token_emb + pos_emb\n",
    "    logits = lm_head(x)\n",
    "\n",
    "    # take logits of last time step\n",
    "    logits_last = logits[:, -1, :]\n",
    "    probs = F.softmax(logits_last, dim=-1)\n",
    "\n",
    "    # sample from distribution\n",
    "    next_token = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "    # append to generated sequence\n",
    "    generated = torch.cat([generated, next_token], dim=1)\n",
    "\n",
    "print(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f1ffd06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KAgervaike wike wike hanmaikencikesers ye mankes wike maikesike wike chy upomanoncikervancaj ancikesese wikethike noty mancike hancike fffentanonoke ffrike wike cike upomuporotye upomant ffffe mantant\n"
     ]
    }
   ],
   "source": [
    "decoded = ''.join([itos[int(i)] for i in generated[0].tolist()])\n",
    "print(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ef2d9ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1360057592391968\n"
     ]
    }
   ],
   "source": [
    "for step in range(10000):\n",
    "    B, T = xb.shape\n",
    "    token_emb = token_embedding_table(xb)                        # (B, T, C)\n",
    "    position_emb = token_position_table(torch.arange(T))  # (T, C)\n",
    "    x = token_emb + position_emb                                 # (B, T, C)\n",
    "\n",
    "    logits = lm_head(x)                                          # (B, T, vocab)\n",
    "    B, T, C = logits.shape\n",
    "    logits = logits.view(B*T, C)\n",
    "    targets = yb.view(B*T)\n",
    "\n",
    "    loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "    # Gradient reset\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    # Backward\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    lr = 1e-3\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc3950",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training a model\n",
    "for steps in range(10000):\n",
    "    xb,yb = get_batch('train')\n",
    "    logits, loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee55e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: torch.Size([256, 65])\n",
      "targets: torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.4113, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B,T,C = logits.shape\n",
    "logits3 = logits.view(B*T,C)\n",
    "print(\"logits:\",logits3.shape)\n",
    "targets = yb.view(B*T)\n",
    "print('targets:',targets.shape)\n",
    "F.cross_entropy(logits3, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1c421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea4caa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: tensor([[-0.0929, -1.3390, -1.8530,  ...,  0.7327, -0.0828,  0.3238],\n",
      "        [ 0.6940, -0.1655,  0.6275,  ..., -0.1051, -0.2384, -0.8234],\n",
      "        [ 0.6146,  1.3971,  0.7296,  ...,  0.5760,  0.8021,  0.4972],\n",
      "        ...,\n",
      "        [ 1.0967,  0.7229,  0.1110,  ...,  0.0170,  1.9136,  0.7253],\n",
      "        [ 0.9462, -0.4075, -0.4941,  ..., -0.2246,  0.6021,  0.7631],\n",
      "        [-0.2758, -0.7347, -0.0909,  ..., -0.9703,  0.7193, -0.0722]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "loss: tensor(4.4489, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([256, 65])\n"
     ]
    }
   ],
   "source": [
    "# Constructing the bigram model\n",
    "## In the Bigram model it does not really matter the position since you will only be contructing or predicting based on the one character before\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_emb) # this is random initialization which will be learned during training.\n",
    "        self.token_position_embedding_table = nn.Embedding(block_size, n_emb) # position embedding of one batch in the context\n",
    "        self.lm_head = nn.Linear(n_emb, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B,T) tensor of integers where idx is xb and targets is yb\n",
    "        B,T = idx.shape # B-Batch, T-Tokens, C-Channel i.e. dimensions\n",
    "        token_emb = self.token_embedding_table(idx)  # (B,T,C) (32,8,32)\n",
    "        position_emb = self.token_position_embedding_table(torch.arange(T)) ## for each block is arrange as 0,1,2,3\n",
    "        x = token_emb + position_emb\n",
    "        logits = self.lm_head(x) # xW.transpose() + b \n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens): # Throw-away variable in loops so it does not fill the variable memory.\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx) # Calls the Forward method\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # (B,C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)  # (B,C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B,1) #  draws a sample from the probability distribution. It returns the index of the next chosen token.\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B,T+1)\n",
    "        return idx\n",
    "\n",
    "n_emb = 32 # this is basically the dimensions size\n",
    "batch_size = 32\n",
    "m = BigramLanguageModel()\n",
    "logits, loss = m(xb, yb) # PyTorch overloads the __call__() method of nn.Module. This calls the forward() method. \n",
    "print(\"logits:\", logits)\n",
    "print(\"loss:\", loss)\n",
    "print(logits.shape) # (B*T, C)\n",
    "# print(targets.shape) # (B*T, C)\n",
    "# torch.zeroes is for new line character so we can initialize the generation from it.\n",
    "# This is completely random generation as the model is untrained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30b825a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7629,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-3.3334, -1.6556,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-1.0226, -1.2606,  0.0762,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.7836, -0.8014, -0.3368, -0.8496,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-1.2566,  0.0187, -0.7880, -1.3204,  2.0363,    -inf,    -inf,    -inf],\n",
      "        [-0.3126,  2.4152, -0.1106, -0.9931,  3.3449, -2.5229,    -inf,    -inf],\n",
      "        [ 1.0876,  1.9652, -0.2621, -0.3158,  0.6091,  1.2616, -0.5484,    -inf],\n",
      "        [-1.8044, -0.4126, -0.8306,  0.5898, -0.7987, -0.5856,  0.6433,  0.6303]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
      "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
      "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.1571,  0.8801,  0.1615, -0.7824, -0.1429,  0.7468,  0.1007, -0.5239,\n",
      "         -0.8873,  0.1907,  0.1762, -0.5943, -0.4812, -0.4860,  0.2862,  0.5710],\n",
      "        [ 0.6764, -0.5477, -0.2478,  0.3143, -0.1280, -0.2952, -0.4296, -0.1089,\n",
      "         -0.0493,  0.7268,  0.7130, -0.1164,  0.3266,  0.3431, -0.0710,  1.2716],\n",
      "        [ 0.4823, -0.1069, -0.4055,  0.1770,  0.1581, -0.1697,  0.0162,  0.0215,\n",
      "         -0.2490, -0.3773,  0.2787,  0.1629, -0.2895, -0.0676, -0.1416,  1.2194],\n",
      "        [ 0.1971,  0.2856, -0.1303, -0.2655,  0.0668,  0.1954,  0.0281, -0.2451,\n",
      "         -0.4647,  0.0693,  0.1528, -0.2032, -0.2479, -0.1621,  0.1947,  0.7678],\n",
      "        [ 0.2510,  0.7346,  0.5939,  0.2516,  0.2606,  0.7582,  0.5595,  0.3539,\n",
      "         -0.5934, -1.0807, -0.3111, -0.2781, -0.9054,  0.1318, -0.1382,  0.6371],\n",
      "        [ 0.3428,  0.4960,  0.4725,  0.3028,  0.1844,  0.5814,  0.3824,  0.2952,\n",
      "         -0.4897, -0.7705, -0.1172, -0.2541, -0.6892,  0.1979, -0.1513,  0.7666],\n",
      "        [ 0.1866, -0.0964, -0.1430,  0.3059,  0.0834, -0.0069, -0.2047, -0.1535,\n",
      "         -0.0762,  0.3269,  0.3090,  0.0766,  0.0992,  0.1656,  0.1975,  0.7625],\n",
      "        [ 0.1301, -0.0328, -0.4965,  0.2865,  0.2704, -0.2636, -0.0738,  0.3786,\n",
      "          0.0746,  0.0338,  0.0147,  0.3194,  0.2993, -0.1653, -0.0386,  0.3375]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Self Attention Mechanism, we require key, query, and values\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch time channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias = False)\n",
    "query = nn.Linear(C, head_size, bias = False)\n",
    "value = nn.Linear(C, head_size, bias = False)\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "\n",
    "wei = q @ k.transpose(-2,-1)\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "print(wei[0])\n",
    "wei = F.softmax(wei, dim = -1)\n",
    "print(wei[0])\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "print(out[0])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74807764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "360fb1bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6226470b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacec_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
